\documentclass{crypto-exercise}
\author[Formalisation of folklore]{Sven Laur}
\contributor[Created and solved]{Sven Laur}
\contributor[Alternative re-randomisation construction]{Ehsan Ebrahimi}
\editor{Sven Laur}
\tags{Decisional Diffie-Hellman problem, random self-reducibility, success amplification}

\newcommand{\RERAND}{\mathscr{R}}

\begin{document}
\begin{exercise}{Random self-reducibility of DDH}
  Let $\GG=\langle g\rangle$ be a finite group of a prime order $q$
  generated by the powers of an element $g$. Then the Decisional
  Diffie-Hellman (DDH) problem is following. For any triple
  $x,y,z\in\GG$, you must decide whether it is a Diffie-Hellman triple
  or not. Formally, the corresponding distinguishing task is specified
  through two games:
  \begin{align*}
   &\begin{game}{\BGAME_0^{\ADB}}
      & a, b\getsu \ZZ_q\\
      & c \getsu \ZZ_q\\
      & \RETURN \ADB(g^a,g^b,g^c)
    \end{game}
   &&\begin{game}{\BGAME_1^{\ADB}}
      & a, b \getsu \ZZ_q\\
      & c \gets ab\\
      & \RETURN \ADB(g^a,g^b,g^c)
    \end{game}
  \end{align*}
  where the advantage is computed as
  $\ADVDDH{\GG}{\AD}=\abs{\pr{\smash{\GAME_0^\AD=1}}-\pr{\smash{\GAME_1^\AD=1}}}$.
  Show that DDH problem is random self-reducible and sketch how to
  amplify the success probability by majority voting.
\end{exercise}
  

\begin{solution}  
  For a solution, we first discuss what random self-reducibility means
  in the context of Decisional Diffie-Hellman problem. Then we show
  how to achieve random self-reducibility and what are the
  consequences. As a last step, sketch how to amplify the success
  probability by majority voting.  



\paragraph{Definition of Random Self-reducibility.}
It is easy to formalise random self-reducibility for a discrete logarithm or Computational Diffie-Hellman problem, as the problem is formalized through a single game. 
For a Decisional Diffie-Hellman problem, we have two security games $\BGAME_0$ and $\BGAME_1$. 
Still, we could require existence of an algorithm $\AD^{\ADB}$ such that for any challenge tuple $g^{a_0},g^{b_0},g^{c_0}$ generated in the $\GAME_0$ and a challenge tuple $g^{a_1},g^{b_1},g^{c_1}$ generated in the $\GAME_1$, the corresponding advantage
\begin{align*}
    \ADV(\AD)=\abs{\pr{\smash{\AD(g^{a_0},g^{b_0},g^{c_0})=1}}-\pr{\smash{\AD(g^{a_1},g^{b_1},g^{c_1})=1}}}
    =\ADVDDH{\GG}{\ADB}\enspace.
\end{align*}
However, such a goal is clearly unachievable since a valid Diffie-Hellman tuple $g^{a_1},g^{b_1},g^{c_1}$ can is also generated in the game $\GAME_0$, as well.
Consequently, more details are needed in the formalisation.

Note that all triples $\GG\times\GG\times\GG$ can be divided into Diffie-Hellman triples and non-Diffie-Hellman triples. To show random self-reducibility for a decision problem, we must provide a re-randomisation algorithm $\RERAND$, which takes any DH triple to a random DH triple and any non-DH triple to a random non-DH triple. Then it is straightforward to construct $\AD$ as $\ADB(\RERAND(x,y,z))$ such that
\begin{align*}
 \ADV(\AD)\approx \ADVDDH{\GG}{\ADB}
\end{align*}
for any $(g^{a_0},g^{b_0},g^{c_0})$  non-DH tuple and $(g^{a_1},g^{b_1},g^{c_1})$  DH tuple pair. 
However note that we do not obtain the precise equality as $\ADB$ sees only random non-DH tuples and not random group elements as in the game $\BGAME_0$.
To fix this cosmetic issue we might require that the  re-randomisation algorithm $\RERAND$, must take any DH triple to a random DH triple and any non-DH triple to a random triple. Then 
\begin{align*}
 \ADV(\AD) = \ADVDDH{\GG}{\ADB}
\end{align*}
for any $(g^{a_0},g^{b_0},g^{c_0})$  non-DH tuple and $(g^{a_1},g^{b_1},g^{c_1})$  DH tuple pair as desired.
  
\paragraph{Construction for random self-reducibility.}
Let $\GG$ be a $q$-element group and $(x,y,z)$ either a DH or non-DH tuple. Then the following re-randomisation algorithm
\begin{align*}
    \begin{fblock}{\RERAND(x,y,z)}
      &u,v,w\getsu\ZZ_q\\
      &x_*\gets x^w g^u\\
      &y_*\gets y g^v \\
      &z_*\gets z^wx^{vw}y^u g^{uv} \\
      &\RETURN (x_*,y_*,z_*)
    \end{fblock}
\end{align*}
takes DH triple to a random DH triple and non-DH triple to a random triple.

\paragraph{Analysis.}
By looking discrete logarithms we can simplify further analysis. 
Let us use shorthands
\begin{align*}
\begin{aligned}
a&=\log(x)\\
b&=\log(y)\\
c&=\log(z)
\end{aligned}
\qquad\qquad
\begin{aligned}
a_*&=\log(x_*)\\
b_*&=\log(y_*)\\
c_*&=\log(z_*)
\end{aligned}
\end{align*}
for denoting discrete logarithms for the inputs and outputs. 
Then $(x,y,z)$ is a DH triple iff $ab = c$ and $(x_*,y_*,z_*)$ is a DH triple iff $a_*b_*=c_*$. By the construction of re-randomiser
\begin{align*}
a_*&=aw+u\\
b_*&=b+v\\
c_*&=cw+awv+bu+uv\enspace,
\end{align*}
and thus
\begin{align*}
a_*b_*-c_*=(aw+u)(b+v)-cw-awv-bu-uv= (ab-c)w\enspace.
\end{align*} 
Consequently, the re-randomisation algorithm returns a DH triple whenever the input $(x,y,z)$ is a DH triple. As $a_*$ and $b_*$ are independent and uniformly distributed over $\ZZ_q$, re-randomisation returns all DH tuples with uniform probability. If $(x,y,z)$ is non-DH triple, then $ab\neq c$ then the output can be any triple. Indeed, the system of linear equations 
\begin{align}
\label{eq:io-map}
\begin{aligned}
a_*&=aw+u\\
b_*&=b+v\\
c_*&=cw+awv+bu+uv
\end{aligned}
\end{align}
can be solved for any target $(a_*,b_*,c_*)$ by taking
\begin{align*}
v&=b_*-b \\
w&=\frac{a_*b_*-c_*}{ab-c}\\
u&=\frac{a_*(ab-c)-a(a_*b_*-c_*)}{ab-c}\enspace.
\end{align*}
As each of those combinations $(u,v,w)$ have equal probability by the construction of $\RERAND$, the distribution of $(x_*,y_*,z_*)$ must be uniform over $\GG\times\GG\times\GG$. 
 

\paragraph{Smoothed distinguisher.}
Given a re-randomiser $\RERAND$ and a distinguisher $\ADB$ we can construct a distinguisher
\begin{align*}
    &\begin{fblock}{\AD(x,y,z)}
      & (x_*,y_*,z_*)\gets \RERAND(x,y,z)\\
      &\RETURN \ADB(x_*,y_*,z_*)
    \end{fblock}
\end{align*}
that works equally well for all DH-tuple vs non-DH tuple pairs. Indeed, for a DH tuple $(x,y,z)$ the new challenge $(x_*,y_*,z_*)$ is uniformly chosen DH-tuple and thus the program is equivalent to  
\begin{align*}
   &\begin{game}{\BGAME_1^{\ADB}}
      & a_*, b_*\getsu \ZZ_q\\
      & c_* \gets a b\\
      & \RETURN \ADB(g^{a_*},g^{b_*},g^{c_*})\enspace.
    \end{game}
\end{align*}  
For a non-DH tuple the new challenge $(x_*,y_*,z_*)$ is uniformly chosen over $\GG\times\GG\times\GG$ and thus the program is equivalent to  
\begin{align*}
   &\begin{game}{\BGAME_0^{\ADB}}
      & a_*, b_*\getsu \ZZ_q\\
      & c_* \getsu \ZZ_q\\
      & \RETURN \ADB(g^{a_*},g^{b_*},g^{c_*})\enspace.
    \end{game}
\end{align*} 
Consequently, we have obtained the desired bound $\ADV(\AD)=\ADVDDH{\GG}{\ADB}$.

 
 
\paragraph{Alternative construction for random self-reducibility.}
Note that the re-randomisation algorithm $\RERAND$ completely ignores the  input $z$ whenever $w=0$ and fabricates a DH-tuple even if the input is not a DH tuple. 
By correcting this error we obtain a new re-randomisation algorithm  
\begin{align*}
    \begin{fblock}{\RERAND^*(x,y,z)}
      &w\getsu\ZZ_q^*\\ 
      &u,v\getsu\ZZ_q\\
      &x_*\gets x^w g^u\\
      &y_*\gets y g^v \\
      &z_*\gets z^wx^{vw}y^u g^{uv} \\
      &\RETURN (x_*,y_*,z_*)
    \end{fblock}
\end{align*}
that still takes DH triple to a random DH triple and non-DH triple to a random non-DH triple. 
The previous argumentation remains intact.
In particular, the analysis if the input is a DH-tuple is identical.
For non-DH tuples, most of the results still hold. 
In particular, $a_*b_*-c_*=(ab-c)w$ is nonzero for all $w\in\ZZ_q^*$ and thus $(x_*,y_*,z_*)$ cannot be a DH triple. 
The output must have uniform distribution over non-DH triples, as the solution $(u,v,w)$ to system of linear equations~\eqref{eq:io-map} satisfies the constraint $w\neq 0$ for all non-DH tuples.

\paragraph{Smoothed distinguisher.} By combining the re-randomiser $\RERAND^*$ and distinguisher, we obtain a distinguisher
\begin{align*}
    &\begin{fblock}{\AD^*(x,y,z)}
      & (x_*,y_*,z_*)\gets \RERAND^*(x,y,z)\\
      &\RETURN \ADB(x_*,y_*,z_*)\enspace,
    \end{fblock}
\end{align*}
which works slightly differently from $\AD$ when the input is non-DH tuple. More precisely, $(x_*,y_*,z_*)$ is distributed uniformly over non-DH tuples instead of uniform distribution over $\GG\times\GG\times\GG$. 
As the statistical distance between these distributions is $\frac{1}{q}$, we get
$\ADV(\AD)\geq\ADVDDH{\GG}{\ADB}-\frac{1}{q}$.  
 
\paragraph{Amplification by majority voting.} 
For clarity, we give the simplest construction where $\ADB$ is called out trice to amplify the distinguishing advantage. 
As before, let $\AD$ denote the reduction algorithm for random self-reducibility. 
Then the new majority voting algorithm is the following:
\begin{align*}
    \begin{fblock}{\ADC(x,y,z)}
      &b_1\gets\AD(x,y,z)\\
      &b_2\gets\AD(x,y,z)\\
      &b_3\gets\AD(x,y,z)\\
      &\RETURN [b_1+b_2+b_3>1]\enspace.
    \end{fblock}
\end{align*}
  
\paragraph{Analysis.}
The same advantage $\ADVDDH{\GG}{\ADB}$ can be achieved with different success probabilities
\begin{align*}
\varepsilon_0&=\pr{\BGAME_1^\ADB=1}\\
\varepsilon_1&=\pr{\BGAME_1^\ADB=1}
\end{align*}
as long as $\ADVDDH{\GG}{\ADB}=\abs{\varepsilon_1-\varepsilon_0}$ and thus the analysis is not so straightforward as one might expect. 
If $(x,y,z)$ is a DH tuple, then we know by previous analysis that
\begin{align*}
    \pr{b_i=1}=\pr{\smash{\BGAME_1^\ADB=1}}=\varepsilon_1\enspace
\end{align*}
and thus 
\begin{align*}
\pr{\smash{\ADC(g^a,g^b,g^{c})=1}|c=ab}=\varepsilon_1^3 +3\varepsilon_1^2(1-\varepsilon_1)\enspace.
\end{align*}
If $(x,y,z)$ is not a DH tuple, then 
\begin{align*}
    \pr{b_i=1}=\pr{\smash{\BGAME_0^\ADB=1}}=\varepsilon_0\enspace
\end{align*}
and thus
\begin{align*}
    \pr{\ADC(g^a,g^b,g^c)=1|c\neq ab}%
    =\varepsilon_0^3 +3\varepsilon_0^2(1-\varepsilon_0)\enspace.
\end{align*}
By combining results
\begin{align*}
\ADV(\ADC)&
=\abs{\varepsilon_0^3 +3\varepsilon_1^2(1-\varepsilon_1)-\varepsilon_0^3 +3\varepsilon_0^2(1-\varepsilon_0)}\\
    &=\abs{2(\varepsilon_1 -
      \varepsilon_0)(\varepsilon_1^2 + \varepsilon_1\varepsilon_0 +
      \varepsilon_0^2)
      - 3(\varepsilon_1 - \varepsilon_0)(\varepsilon_1 + \varepsilon_0)}\\
    &=\abs{\varepsilon_1 - \varepsilon_0}
    \cdot \abs{\smash{3\varepsilon_0 +3\varepsilon_1 -
        2\varepsilon_0^2 - 2\varepsilon_0\varepsilon_1 -
        2\varepsilon_0^2}}
\end{align*}
and thus
\begin{align*}
    \ADVDDH{\GG}{\ADC}%
    &=\ADVDDH{\GG}{\ADC}\cdot
    \abs{\smash{3\varepsilon_0 +3\varepsilon_1 - 2\varepsilon_0^2 -
        2\varepsilon_0\varepsilon_1 - 2\varepsilon_0^2}}\enspace.
\end{align*}
The last term can be lower bounded further if we assume that $\ADVDDH{\GG}{\AD}\in\bigl(\frac{1}{2},\frac{3}{4}\bigr)$. Then  
\begin{align*}
    \ADVDDH{\GG}{\ADC}&=
    \ADVDDH{\GG}{\ADC}^2 \cdot (3 - 2\cdot\ADVDDH{\GG}{\AD} )
    >\ADVDDH{\GG}{\AD}\enspace.
\end{align*}
and we indeed do get amplification of success probability. 
However, the gain is not so big and the derivation of the advantage is not so straightforward as it seems.

\paragraph{Further comments.} The reduction construction $\ADC$ is not optimal for the analysis. Usually, one uses more complex indirect construction
  \begin{align*}
    \begin{fblock}{\ADC(x,y,z)}
      &\overline{z}\getsu\GG\\
      & i_1,i_1,i_3\getsu\set{0,1}\\
      &\IF i_1=1\ \THEN b_1\gets\AD(x,y,z)\ \ELSE  b_1\gets\AD(x,y,\overline{z}) \\
      &\IF i_2=1\ \THEN b_2\gets\AD(x,y,z)\ \ELSE  b_2\gets\AD(x,y,\overline{z}) \\
      &\IF i_3=1\ \THEN b_3\gets\AD(x,y,z)\ \ELSE  b_3\gets\AD(x,y,\overline{z}) \\
      &\IF [b_1\iseq i_1]+[b_2\iseq i_2]+[b_3\iseq i_3]>1\ \THEN \RETURN 1\\
      &\ELSE \RETURN 0
    \end{fblock}
  \end{align*}
\end{solution}
which allows to reduce the analysis on the analysis of biased coin throws and use Chebyshev or Hoeffding bounds to estimate the success of majority voting. 
\end{document}
