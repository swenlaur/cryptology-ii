\documentclass{crypto-exercise}
% \documentclass[11pt]{article}
% \usepackage{color} %used for font color
% \usepackage{amssymb} %maths
% \usepackage{amsmath} %maths
% \usepackage[utf8]{inputenc} %useful to type directly accentuated characters
% \usepackage{graphicx}
% \usepackage[draft]{crygame}
% \usepackage{crysymb}
% \usepackage{crypto-ii}
% \usepackage{exercise-layout}
% \usepackage{algorithmic}




\begin{document}
\sloppy

\section{Exercise Sheet 1}

\begin{exercise}{Electronic lottery}
  A company holds electronic lotteries briefly described below. A
  secure hardware is used to generate the output $x\in \set{0,
    1}^{20}$.  The input $x$ is fed into a specially designed garbling
  algorithm (worldwide patented), which takes in $x$ and broadcasts a
  garbled output $y$ to everybody. All participants submit their
  guesses $q_i$ about $x$. The company releases $x$ and everybody uses
  the description of the garbling algorithm to verify that y was
  computed form $x$. The one who guessed $x$ gets a prize.
\begin{enumerate}
\item Formalize the lottery system using abstract primitives for appropriate
actions. Describe such functional requirements that the organizer
cannot cheating and that participants can verify the correctness.
\item Define an attack scenario where participants try to cheat. Quantify
the success of the malicious participant. Formalize the corresponding
security definition.
\item Show that no garbling algorithm can meet functional requirements
and be secure at the same time.
\end{enumerate}
\end{exercise}

\withsolution{
\begin{solution}\ \\
  1. The lottery system can be viewed as the following public function
  $f: \set{0,1}^{20}\rightarrow \YYY$.
\begin{figure}[h]
	\begin{center}
	\includegraphics[scale=0.8]{figures/Ex1}
	\end{center}
\end{figure}
We say that the organizer cannot cheat if and only if for all p.p.t. adversaries $\AAA$ has negligible probability to win the following game:
\begin{align*}
  & \begin{game}{G_1^{\AAA}}
    &  (x_1,x_2) \gets \AAA^{f(\cdot)}\\
    & \RETURN [ x_1 \neq x_2 \wedge f(x_1) = f(x_2) ]
  \end{game} 
&
\end{align*}
2. We say that the participants cannot cheat if and only if for all
efficient adversaries $\AAA$ has negligible probability to win the
following game:
\begin{align*}
  & \begin{game}{G_2^{\AAA}}
    &  x \gets \set{0,1}^{20} \\
    & x^* \gets  \AAA^{f(\cdot)}(f(x))\\
    & \RETURN [ x^* = x ]
  \end{game} 
&
\end{align*}
To be concrete, lets postulate that a program is effective if your
computer can execute it in one day and a probability is negligible if
it is below $10^{-6}$. You will be murdered in a year with this
probability and yet you do not worry about it.

3. Assume that there is no adversary can win game $G_1$, i.e. the
function $f$ is injective. Therefore, given $y$, there is a unique $x$
such that $f(x)=y$. We show that the adversary $\AAA$ can win game
$G_2$: given input $x$, $\AAA$ tries all possible $x\in\set{0,1}^{20}$
and outputs the value if $f(x)=y$. Hence, with running time $2^{20}$,
the adversary $\AAA$ has probability $1$ to win $G_2$.

On the other hand, if we assume that there is no adversary can win
game $G_2$ with probability $p$, then there must exist $x'$ such that
$x'\neq x \wedge f(x')=f(x)$. Similarly, the adversary can win the
game $G_1$ by finding a different pre-image with running time
$2^{20}$.  
\end{solution}
}



\begin{exercise}{Security of hash functions}
  A standard way to protect data against malicious corruption is
  hashing. Namely, there are many industry standard algorithms, like
  MD5, SHA-256 and WHIRLPOOL, that take in a long file and output a
  short digest. If the digest is securely stored, then the validity of
  the file can be tested by recomputing the digest and comparing it to
  the stored value.
  \begin{enumerate}
  \item Formalise the functional requirements and describe the attack
    scenario if the original data is generated by flipping a fair coin.
  \item Describe the attack scenario if an attacker gets to know the
    randomly generated original data before spoofing the file. 
  \item Describe the attack scenario if attacker can influence the
    content of the original file. Show that no function can be secure
    against such attacks. What does it mean in real life applications?
  \end{enumerate}
\end{exercise}



\withsolution{
  \begin{solution} \ \\
    1. Denote the hash function as $h: \set{0,1}^{*}\rightarrow \DDD$,
    where $\DDD$ is the digest space. Let $\MSPACE$ be a message
    space. The attack scenario can be modeled as the following game:
\begin{align*}
  & \begin{game}{G^{\AAA}}
    &  x \gets \MSPACE \\
    & x^* \gets  \AAA^{h(\cdot)}(h(x))\\
    & \RETURN [h(x^*)=h(x)]
  \end{game} 
&
\end{align*}
2. The attack scenario can be modeled as the following game:
\begin{align*}
  & \begin{game}{G^{\AAA}}
    &  x \gets \MSPACE\\
    & x^* \gets  \AAA^{h(\cdot)}(x)\\
    & \RETURN [ x^* \neq x \wedge h(x^*)=h(x)]
  \end{game} 
&
\end{align*}
3. The attack scenario can be modeled as the following game:
\begin{align*}
  & \begin{game}{G_3^{\AAA}}
    & (x_1,x_2) \gets  \AAA^{h(\cdot)}()\\
    & \RETURN [ x_1 \neq x_2 \wedge h(x_1)=h(x_2) ]
  \end{game} 
&
\end{align*}
 
Since $h(\cdot)$ is fixed in the game $G_3$, there exists an
\emph{extremely efficient} adversary $\AAA$ which just prints $x_1$
and $x_2$ such that $h(x_1)=h(x_2)$. Therefore, no function can be
secure for such game. However, in reality, we know such adversary
exists, but we have no idea how to find such adversary, so there is
practical influence under such attack.
\end{solution}
}%end solution



\begin{exercise}{Security of standard password hashing}
  Salted hashing is common mechanism for storing passwords. Each
  user is first granted an identifier \texttt{id}. Every time the
  password is hashed, the identifier \texttt{id} is appended to it and
  then a system-wide hash function is used to compute the digest. The
  authentication is successful if the digest coincides with the digest
  stored in \texttt{passwd} file.
  \begin{enumerate}
  \item Formalise the system by using abstract primitives for
    appropriate actions. Describe the functional requirements that are
    needed for seamless authentication. Compare the formalisation with
    the lottery system described in the first exercise.
  \item Define an attack scenario where the attacker tries to reverse
    engineer passwords from salted hashes. Formalise the corresponding
    security condition. Can this security condition be met in
    practice?
  \item Extend the attack description to the setting where the
    identifier \texttt{id} depends on the identity of a user. What
    does such a design choice give to the attacker? Modify the
    corresponding attack scenario and derive the corresponding
    security requirement.
  \end{enumerate}
\end{exercise}


\withsolution{
  \begin{solution} \ \\
    1. Denote the hash function as $h: \set{0,1}^{*}\rightarrow \DDD$,
    where $\DDD$ is the digest space. Let $\MSPACE$ be the password
    space. The attack scenario can be modeled as the following game:
\begin{align*}
  & \begin{game}{G^{\AAA}}
   &  \texttt{id}\gets \AAA^{h(\cdot)} \\
    & (x_1,x_2) \gets  \AAA^{h(\cdot)}(\texttt{id})\\
    & \RETURN [x_1 \neq x_2 \wedge h(x_1|| \texttt{id})=h(x_2|| \texttt{id})]
  \end{game} 
&
\end{align*}
2. The attack scenario can be modeled as the following game:
\begin{align*}
  & \begin{game}{G^{\AAA}}
    &  x \gets \MSPACE\\
    & \texttt{id} \gets \set{0,1}^\ell \\
    & (x^*, \texttt{id}^*) \gets  \AAA^{h(\cdot)}(h(x||\texttt{id}))\\
    & \RETURN [ h(x||\texttt{id}) = h(x^*||\texttt{id}^*) ]
  \end{game} 
&
\end{align*}
3. The attack scenario can be modeled as there exists no p.p.t. adversary $\AAA$ can win the following game:
\begin{align*}
  & \begin{game}{G^{\AAA}}
   &  \texttt{id}\gets \AAA^{h(\cdot)} \\
    &  x \gets \MSPACE\\
    & x^* \gets  \AAA^{h(\cdot)}(h(x||\texttt{id}))\\
    & \RETURN [  h(x||\texttt{id}) = h(x^*||\texttt{id}) ]
  \end{game} 
&
\end{align*}
\end{solution}
}%end solution



\begin{exercise}{Random self-reducibility}
  Let $\GG$ be a finite group such that all elements $y\in\GG$ can be
  expressed as powers of $g\in\GG$. Then the Computational
  Diffie-Hellman (CDH) problem is following. Given $x=g^a$ and
  $y=g^b$, find a group element $z=g^{ab}$.
  \begin{enumerate}
  \item Show that Computational Diffie-Hellman problem is random
    self-reducible, i.e., for any algorithm $\ADB$ that achieves
    advantage
    \begin{align*}
      \advCDHXX{\GG}{\ADB}\doteq\pr{x,y\getsu\GG: \ADB(x,y)=g^{\log_g
          x\log_g y}}
    \end{align*}
    there exists an oracle algorithm $\AD^{\ADB}$ that for any input
    $x,y\in\GG$ outputs the correct answer with the probability
    $\advCDHXX{\GG}{\ADB}$ and has roughly the same running time.
  \item Given that the CDH problem is random self-reducible, show that
    the difficulty of CDH instances cannot wary a lot. Namely, let
    $\ADB$ be a $t$-time algorithm that achieves maximal advantage
    $\advCDHXX{\GG}{\ADB}$. What can we say about worst-case advantage
    \begin{align*}
      \min_{x,y}\pr{\AD(x,y)=g^{\log_g x\log_g y}}?
    \end{align*}
    Can there be a large number of pairs $(x,y)$ for which the CDH problem
    is easy?
  \end{enumerate}
\end{exercise}
  
\withsolution{
\begin{solution}  
  
  For a solution, we first discuss what random self-reducibility means
in the context of Decisional Diffie-Hellman problem. Then we show how
to achieve random self-reducibility and what are the consequences. As
a last step, show how to amplify the success probability by majority
voting.
\bigskip

\noindent\textsc{Random Self-reducibility.}
It is easy to formalise random self-reducibility for a discrete
logarithm or Computational Diffie-Hellman problem, since we can
formalise the goal through a single game. For a Decisional
Diffie-Hellman problem, the formalisation is not so
straightforward. Recall that the canonical advantage against the
Decisional Diffie-Hellman problem
\begin{align*}
  \advDDHXX{\GG}{\AD}=\abs{\pr{\GAME_0^\AD=1}-\pr{\GAME_1^\AD=1}}
\end{align*}
 is defined through two games
\begin{align*}
  &\begin{game}{\GAME_0^\AD}
    &a,b\getsu\ZZ_q\\
    &c\getsu\ZZ_q\\
    &\RETURN \AD(g^a,g^b,g^c)
  \end{game}
 &&\begin{game}{\GAME_1^\AD}
    &a,b\getsu\ZZ_q\\
    &c\gets ab\\
    &\RETURN \AD(g^a,g^b,g^c)
  \end{game}
\end{align*}
So ideally we would like to have an algorithm $\ADB$ such that for any
challenge tuple $g^{a_0},g^{b_0},g^{c_0}$ generated in the $\GAME_0$
and a challenge tuple $g^{a_1},g^{b_1},g^{c_1}$ generated in the
$\GAME_1$, the corresponding advantage
\begin{align*}
  \ADV(\ADB)=\abs{\pr{\ADB(g^{a_0},g^{b_0},g^{c_0})}-\pr{g^{a_1},g^{b_1},g^{c_1}}}
   =\advDDHXX{\GG}{\AD}\enspace.
\end{align*}
However, such goal is clearly unachievable since a valid
Diffie-Hellman tuple $g^{a_1},g^{b_1},g^{c_1}$ can is also generated
in the game $\GAME_0$, as well. Consequently, we formalise the random
self-reducibility of a Decisional Diffie-Hellman problem a bit
differently.  An instance of Decisional Diffie-Hellman problem is
\emph{randomly self-reducible} if for any algorithm $\AD$ there exists
an algorithm $\ADB$ with comparable running-time such that
\begin{align*}
  \ADV(\ADB)=\abs{\pr{\ADB(g^{a_0},g^{b_0},g^{c_0})}-\pr{g^{a_1},g^{b_1},g^{c_1}}}
   =\advDDHXX{\GG}{\AD}
\end{align*}
whenever $(g^{a_1},g^{b_1},g^{c_1})$ is a Diffie-Hellman tuple and
$(g^{a_0},g^{b_0},g^{c_0})$ is not a Diffie-Hellman tuple. 

\bigskip
\noindent\textsc{Reduction construction for random self-reducibility.} 
Let $\GG$ be a $q$-element group and $\AD$ be a distinguisher for the
Decisional Diffie-Hellman problem. Then the following adversary
achieves the desired  guarantees.
\begin{align*}
  \begin{fblock}{\ADB(x,y,z)}
   &u,v,w\gets\ZZ_q\\
   &\overline{x}\gets x^w g^u\\
   &\overline{y}\gets y g^v \\
   &\overline{z}\gets z^wx^{vw}y^u g^{uv} \\
   &\RETURN \AD(\overline{x},\overline{y},\overline{z})
  \end{fblock}
\end{align*}

\bigskip
\noindent\textsc{Analysis.}
Before going any further note that the challenge games can be
rewritten to a bit more convenient form ($c$ is still uniformly
distributed in $\GAME_0$)
\begin{align*}
  &\begin{game}{\GAME_0^\AD}
    &a,b,k\getsu\ZZ_q\\
    &c\gets ab+k\\
    &\RETURN \AD(g^a,g^b,g^c)
  \end{game}
 &&\begin{game}{\GAME_1^\AD}
    &a,b\getsu\ZZ_q\\
    &c\gets ab\\
    &\RETURN \AD(g^a,g^b,g^c)
  \end{game}
\end{align*}
Let us now see what happens if $\ADB$ gets an input
$g^{a_i},g^{b_i},g^{c_i}$. Then by using standard algebraic equalities
we can simplify the algorithm
\begin{align*}
  &\begin{fblock}{\ADB(g^{a_i},g^{b_i},g^{c_i})}
   &u,v,w\getsu\ZZ_q\\
   &\overline{x}\gets g^{a_iw+u}\\
   &\overline{y}\gets g^{b_i+v} \\
   &\overline{z}\gets g^{c_iw+a_ivw+b_iu+ uv} \\
   &\RETURN \AD(\overline{x},\overline{y},\overline{z})
  \end{fblock}  
\end{align*}
As the input $g^{a_1},g^{b_1},g^{c_1}$ is a Diffie-Hellman tuple,
$c_1=a_1b_1$ and we can further simplify the algorithm without
changing its behaviour 
\begin{align*}
  &\begin{fblock}{\ADB(g^{a_1},g^{b_1},g^{c_1})}
   &u,v,w\getsu\ZZ_q\\
   &\overline{x}\gets g^{a_1w+u}\\
   &\overline{y}\gets g^{b_1+v} \\
   &\overline{z}\gets g^{(a_1w+u)(b_i+v)} \\
   &\RETURN \AD(\overline{x},\overline{y},\overline{z})
  \end{fblock}  
  &&\Rightarrow
  &&\begin{fblock}{\ADB(g^{a_1},g^{b_1},g^{c_1})}
   &\alpha,\beta\getsu\ZZ_q\\
   &\overline{x}\gets g^{\alpha}\\
   &\overline{y}\gets g^{\beta} \\
   &\overline{z}\gets g^{\alpha\beta} \\
   &\RETURN \AD(\overline{x},\overline{y},\overline{z})
  \end{fblock}      
\end{align*}
In particular, note that variables $\alpha\gets a_iw+u$ and
$\beta\gets b_i+v$ have uniform distribution over $\ZZ_q$ and thus the
second simplification does not change the behaviour of
$\ADB(g^{a_1},g^{b_1},g^{c_1})$. Since the final form of
$\ADB(g^{a_1},g^{b_1},g^{c_1})$ is equivalent to the game
$\GAME_1^\AD$, we have established that
\begin{align*}
  \pr{\ADB(g^{a_1},g^{b_1},g^{c_1})}=\pr{\GAME_1^\AD=1}\enspace.
\end{align*}

Let us now analyse the case where the input $g^{a_0},g^{b_0},g^{c_0}$
is a Diffie-Hellman tuple, i.e., $c_0=a_0b_0+k$ for some $k\neq 0$ in
$\ZZ_q$. Again, we can use this knowledge to simplify the algorithm
without changing its behaviour
\begin{align*}
  &\begin{fblock}{\ADB(g^{a_0},g^{b_0},g^{c_0})}
   &u,v,w\getsu\ZZ_q\\
   &\overline{x}\gets g^{a_0w+u}\\
   &\overline{y}\gets g^{b_0+v} \\
   &\overline{z}\gets g^{(a_0w+u)(b_i+v)+kw} \\
   &\RETURN \AD(\overline{x},\overline{y},\overline{z})
  \end{fblock}  
  &&\Rightarrow
  &&\begin{fblock}{\ADB(g^{a_0},g^{b_0},g^{c_0})}
   &\alpha,\beta,w\getsu\ZZ_q\\
   &\overline{x}\gets g^{\alpha}\\
   &\overline{y}\gets g^{\beta} \\
   &\overline{z}\gets g^{\alpha\beta+kw} \\
   &\RETURN \AD(\overline{x},\overline{y},\overline{z})
  \end{fblock}      
\end{align*}
To go further with the analysis, we \textbf{have to} assume that $q$
is prime. If this condition is met then $kw$ for $w\getsu\ZZ_q$ has
uniform distribution over $\ZZ_q$. If $q$ is not a prime then such
claim does not hold and the construction \textbf{does not provide}
random self-reducibility. To continue, if $q$ is prime then we can
further simplify the algorithm without changing its behaviour
\begin{align*}
   \begin{fblock}{\ADB(g^{a_0},g^{b_0},g^{c_0})}
     &\alpha,\beta,\gamma\getsu\ZZ_q\\
     &\overline{x}\gets g^{\alpha}\\
     &\overline{y}\gets g^{\beta} \\
     &\overline{z}\gets g^{\alpha\beta+\gamma} \\
     &\RETURN \AD(\overline{x},\overline{y},\overline{z})
 \end{fblock}          
\end{align*}
Since the final form of $\ADB(g^{a_0},g^{b_0},g^{c_0})$ is equivalent
to the game $\GAME_1^\AD$, we have established that
\begin{align*}
    \pr{\ADB(g^{a_0},g^{b_0},g^{c_0})}=\pr{\GAME_0^\AD=1}\enspace.
\end{align*}
Consequently, we have proven that if $\GG$ contains prime number of
elements then
\begin{align*}
    \ADV(\ADB)=\abs{\pr{\GAME_0^\AD=1}-\pr{\GAME_1^\AD=1}}=\advDDHXX{\GG}{\AD}\enspace.
\end{align*}

\bigskip
\noindent\textsc{Amplification by majority voting.} For clarity, we
give the simplest construction where $\AD$ is called out trice to
amplify the distinguishing advantage. As before, let $\ADB$ denote the
reduction algorithm for random self-reducibility. Then the new
majority voting algorithm is the following
\begin{align*}
  \begin{fblock}{\ADC(x,y,z)}
    &b_1\gets\ADB(x,y,z)\\
    &b_2\gets\ADB(x,y,z)\\
    &b_3\gets\ADB(x,y,z)\\
    &\IF b_1+b_2+b_3>1\ \THEN \RETURN 1\\
    &\ELSE \RETURN 0
  \end{fblock}
\end{align*}

\bigskip
\noindent\textsc{Analysis.} 
Let us first consider the probability $\pr{\GAME_1^\ADC=1}$. In the
game $\GAME_1$, all inputs $g^a,g^b,g^c$ for $\ADC$ are Diffie-Hellman
tuples. Let $\varepsilon_1=\pr{\GAME_1^\AD=1}$. Then for any fixed
tuple, we know by previous analysis that
\begin{align*}
  \pr{b_i=1}=\pr{\GAME_1^\AD=1}=\varepsilon_1\enspace.
\end{align*}
Consequently, we get
\begin{align*}
  \pr{\ADC(g^a,g^b,g^c)=1}=\varepsilon_1^3 +3\varepsilon_1^2(1-\varepsilon_1)
\end{align*}
and thus the average success is still the same: 
\begin{align*}
  \pr{\GAME_1^\ADC=1}=\varepsilon_1^3 +3\varepsilon_1^2(1-\varepsilon_1)\enspace.
\end{align*}

As the second step, let us find the probability
$\pr{\GAME_1^\ADC=1}$. As an input is a Diffie-Hellman tuple with
probability $\frac{1}{q}$ in the game $\GAME_0$, we get
\begin{align*}
  \pr{\GAME_1^\ADC=1}=\textstyle\frac{1}{q}\cdot  \pr{\ADC(g^a,g^b,g^c)=1|c=ab}
   +\frac{q-1}{q}\cdot  \pr{\ADC(g^a,g^b,g^c)=1|c\neq ab}\enspace. 
\end{align*}
As the analysis of the first conditional is already done above, we are
left with the case where $g^a,g^b,g^c$ is not a Diffie-Hellman
tuple. Again, let $\varepsilon_0=\pr{\GAME_0^\AD=1}$. Then for any
fixed tuple, we know by previous analysis that
\begin{align*}
  \pr{b_i=1}=\pr{\GAME_0^\AD=1}=\varepsilon_0\enspace.
\end{align*}
Consequently, we get
\begin{align*}
  \pr{\ADC(g^a,g^b,g^c)=1|c\neq ab}=\varepsilon_0^3 +3\varepsilon_0^2(1-\varepsilon_0)
\end{align*}
and thus
\begin{align*}
  \pr{\GAME_0^\ADC=1}=\textstyle\frac{1}{q}\cdot\bigl(\varepsilon_1^3 +3\varepsilon_1^2(1-\varepsilon_1)\bigr)
  +\frac{q-1}{q}\cdot \bigl(\varepsilon_0^3 +3\varepsilon_0^2(1-\varepsilon_0)\bigr)\enspace.
\end{align*}
By combining the results, we get
\begin{align*}
  \advDDHXX{\GG}{\ADC}&=\textstyle\frac{q-1}{q}\cdot
  \abs{\varepsilon_1^3 +3\varepsilon_1^2(1-\varepsilon_1)-\varepsilon_0^3 -3\varepsilon_0^2(1-\varepsilon_0)}\\
  &=\textstyle\frac{q-1}{q}\cdot 
  \abs{2(\varepsilon_1 - \varepsilon_0)(\varepsilon_1^2 + \varepsilon_1\varepsilon_0 + \varepsilon_0^2)
 - 3(\varepsilon_1 - \varepsilon_0)(\varepsilon_1 + \varepsilon_0)}\\
  &=\textstyle\frac{q-1}{q}\cdot\abs{\varepsilon_1 - \varepsilon_0} \cdot
  \abs{\smash{3\varepsilon_0 +3\varepsilon_1 - 2\varepsilon_0^2  - 2\varepsilon_0\varepsilon_1 - 2\varepsilon_0}}
\end{align*}
By the definition $\advDDHXX{\GG}{\AD}=\abs{\varepsilon_0-\varepsilon_1}$ and thus
\begin{align*}
   \advDDHXX{\GG}{\ADC}&=\textstyle\frac{q-1}{q}\cdot \advDDHXX{\GG}{\ADC}\cdot
  \abs{\smash{3\varepsilon_0 +3\varepsilon_1 - 2\varepsilon_0^2  - 2\varepsilon_0\varepsilon_1 - 2\varepsilon_0}}
\end{align*}
where the last term can be lower bounded in the range
$\advDDHXX{\GG}{\AD}\in(\frac{1}{2},\frac{3}{4})$ further
\begin{align*}
   \advDDHXX{\GG}{\ADC}&=\textstyle\frac{q-1}{q}\cdot \advDDHXX{\GG}{\ADC}^2
 \cdot (3 - 2\cdot\advDDHXX{\GG}{\AD} ) >\advDDHXX{\GG}{\AD}\enspace.
\end{align*}
Hence, we do get amplification of success probability. However, the
gain is not so big and the derivation of the advantage is not so
straightforward as it seems. 

\bigskip
\noindent
\textsc{Further comments.} The reduction construction is not optimal
for the analysis. Usually, one uses more complex construction 
\begin{align*}
    \begin{fblock}{\ADC(x,y,z)}
    &\overline{z}\getsu\GG\\
    & i_1,i_1,i_3\getsu\set{0,1}\\
    &\IF i_1=1\ \THEN b_1\gets\ADB(x,y,z)\ \ELSE  b_1\gets\ADB(x,y,\overline{z}) \\
    &\IF i_2=1\ \THEN b_2\gets\ADB(x,y,z)\ \ELSE  b_2\gets\ADB(x,y,\overline{z}) \\
    &\IF i_3=1\ \THEN b_3\gets\ADB(x,y,z)\ \ELSE  b_3\gets\ADB(x,y,\overline{z}) \\
    &\IF [b_1\iseq i_1]+[b_2\iseq i_2]+[b_3\iseq i_3]>1\ \THEN \RETURN 1\\
    &\ELSE \RETURN 0
  \end{fblock}
\end{align*}

\bigskip
\noindent
\textsc{Analysis sketch.}  If $x,y,z$ is not a Diffie-Hellman tuple
then with probability $\frac{q-1}{q}$, the tuple $x,y,\overline{z}$ is
not a Diffie-Hellman tuple and inputs are indistinguishable for
$\ADB$. As a result $\pr{b_j=i_j}\in (\frac{1}{2}-\frac{1}{q},
\frac{1}{2}+\frac{1}{q})$.  If $x,y,z$ is a Diffie-Hellman tuple then
the inputs can be distinguished and thus $\pr{b_j=i_j}\in
(\advDDHXX{\GG}{\AD}-\frac{1}{q}, \advDDHXX{\GG}{\AD}+\frac{1}{q})$.
In other words, the expected value of the sum
\begin{align*}
 [b_1\iseq i_1]+[b_2\iseq i_2]+[b_3\iseq i_3]  
\end{align*}
is higher than $\frac{3}{2}$ and we can use Chebyshev or Hoeffding
bounds to estimate the success. Even the naive method where we
explicitly use that $\pr{b_j=i_j}\in (\advDDHXX{\GG}{\AD}-\frac{1}{q},
\advDDHXX{\GG}{\AD}+\frac{1}{q})$ is enough to get tractable bounds on
the success probability as there is no need to introduce
$\varepsilon_0$ and $\varepsilon_1$.

\qed
\end{solution}
}%end solution

  
\begin{exercise}{Simple reductions for discrete logarithm}
  Let $\GG$ be a finite group such that all elements $y\in\GG$ can be
  expressed as powers of $g\in\GG$. Then the Decisional Diffie-Hellman
  (DDH) problem is following. Given $x=g^a$ and $y=g^b$ and $z$,
  decide whether $z=g^{xy}$ or not.
  \begin{enumerate}
  \item Show that Decisional Diffie-Hellman problem can be reduced to
    Computational Diffie-Hellman problem, i.e., for any algorithm
    $\AD$ that achieves advantage $\advCDHXX{\GG}{\AD}$, there exists
    an oracle algorithm $\ADB^{\AD}$ that has has roughly the same
    running time and that the advantage
    \begin{align*}
      \advDDHXX{\GG}{\ADB}\doteq
      \abs{\pr{\begin{aligned}
        &x,y,z\getsu\GG:\\ 
        &\ADB(x,y,z)=1
      \end{aligned}}-
      \pr{\begin{aligned}
        &x,y\getsu\GG, z\gets g^{\log x\log y}:\\ 
        &\ADB(x,y,z)=1
      \end{aligned}}}
    \end{align*}
    is equal to the advantage $\advCDHXX{\GG}{\AD}$. 
  \item Provide a  reductions between DL, CDH and DDH problems.
  \item Show that if there exists an efficient procedure that can
    always compute the highest bit of $\log_g y$ then the DL problem
    is easy.
  \item[($\star$)] Although the Decisional Diffie-Hellman problem is
    randomly self-reducible, naively re-randomised challenges are
    dependent on each other. Is it possible to construct an algorithm
    that amplifies the advantage by running several instances of the
    base algorithm to provide an aggregated answer. Give a
    construction or a proof that such a construction cannot exist.
  \end{enumerate}
\end{exercise}

\withsolution{
\begin{solution} \ \\
1. We construct $\ADB$ on top of $\AD$ as follows:

\begin{align*}
  \begin{fblock}{\ADB^{\AD}(x,y,z)}
   &z^*\gets \AD(x,y)\\
   &\RETURN [z^* \iseq z]
  \end{fblock}
\end{align*}
Clearly, we have  $ \advDDHXX{\GG}{\ADB} =  \advCDHXX{\GG}{\AD}$ with roughly the same running time as request.\\

2. Assume $\AD$ is an adversary who plays DL game, $\ADB$ is an
adversary who plays DDH game, and $\ADC$ is an adversary who plays CDH
game. Now we show that if $DL$ assumption does not hold in group
$\GG$, so is CDH assumption by the following game.
\begin{align*}
  \begin{fblock}{\ADC^{\AD}(x,y)}
   &a\gets \AD(x)\\
   &\RETURN [y^{a} ]
  \end{fblock}
\end{align*}
Clearly, we have $ \advDLXX{\GG}{\AD} = \advCDHXX{\GG}{\ADC}$. According to transitivity, we can also reduce DDH problem to DL problem, for we already shown DDH $\leq$ CDH in previous exercise.\\

3. Assume $\AD$ is the magic algorithm that can always output the
highest bit of $\log_{g} y$, and let $\log_{g} y$ be an $\ell$ bit
integer.  We will construct an adversary $\ADB$ can solve the DL
problem as follows.

\begin{align*}
  \begin{fblock}{\ADB^{\AD}(y)}
   & x = 0 \\
   & \text{For } i\in[\ell] \text{ do:}\\
   & \text{   1. } \alpha \gets \AD(y)\\
   & \text{   2. } y = (y\cdot  g^{-\alpha \cdot 2^{\ell}})^2\\
   & \text{   3. } x = x || \alpha \\
   &\RETURN [x]
  \end{fblock}
\end{align*}
Note that $\alpha\in\set{0,1}$, so if $\alpha = 0$, we have $y = y^2$
for the next iteration, which shift the exponent left one position. If
$\alpha = 1$, we compute $y = y\cdot g^{-2^\ell}$ to remove the
left-most $1$-bit in the exponent, then we shift left as previous
case.  \qed
\end{solution}
}%end solution

\end{document}
